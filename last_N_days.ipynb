{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5PdetkPKsbP9pmxGXkCwI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cehaletx/pub/blob/main/last_N_days.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is a notebook to work through ingest rates for an elastic cluster.\n",
        "\n",
        "It will connect to the cloud id using the user and pass which it will prompt for then calculate the average doc size and the number of docs for the last\n",
        "N days.\n",
        "\n",
        "First step let's import the right libraries."
      ],
      "metadata": {
        "id": "wg6fa_h_4BCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q elasticsearch\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "from elasticsearch import Elasticsearch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "vcBXnloO4GzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's define some variables, the number of days and the index patterns."
      ],
      "metadata": {
        "id": "bhHeyipH4tCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------------------------------------\n",
        "# not doing any checking but let's get the command line arg. expecting an\n",
        "# integer which is number of days of ingest to calculate\n",
        "#--------------------------------------------------------------------------------\n",
        "#last_n_days = int( sys.argv[1] )\n",
        "last_n_days = int (7)\n",
        "index_pattern=\"*\""
      ],
      "metadata": {
        "id": "v4McxwS646EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's collect the elastic connection credentials\n"
      ],
      "metadata": {
        "id": "jbVw-M6X5RpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ELASTIC_CLOUD_ID=input(\"input your cloud id \")\n",
        "ELASTIC_CLOUD_ID=\"demo-cluster:dXMtZWFzdC0xLmF3cy5mb3VuZC5pbzo0NDMkYThhNGM3NDVlNTU4NGU4OGFmMWQ1OGFkY2E5NTBkN2IkMmIwYTk2ZjY4MDE0NGFjNzk4Y2NiMDA4NjUyMDc0YWE=\"\n",
        "default = \"elastic\"\n",
        "ELASTIC_USERNAME = \"elastic\"\n",
        "#ELASTIC_USERNAME=input(\"input your elastic user [%s] \"%default + chr(8)*4)\n",
        "#if not ELASTIC_USERNAME:\n",
        "#   ELASTIC_USERNAME = default\n",
        "#ELASTIC_PASSWORD=input(\"input your elastic password \")\n",
        "ELASTIC_PASSWORD=\"3QndbuYUwKiyN5EyxZ9IdByN\""
      ],
      "metadata": {
        "id": "gVs6ZWRT94zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = Elasticsearch(\n",
        "    cloud_id=ELASTIC_CLOUD_ID,\n",
        "    timeout=60,\n",
        "    basic_auth=(ELASTIC_USERNAME, ELASTIC_PASSWORD)\n",
        ")"
      ],
      "metadata": {
        "id": "m6Q-ZhO05Vfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup the data class, inititalize some arrays, and define a function to calculate document size"
      ],
      "metadata": {
        "id": "vQ7bhT-n5ayF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class doubleQuoteDict(dict):\n",
        "  def __str__(self):\n",
        "    return json.dumps(self)\n",
        "  def __repr__(self):\n",
        "    return json.dumps(self)\n",
        "\n",
        "# Initialize lists to store data\n",
        "periods = []\n",
        "document_counts = []\n",
        "\n",
        "# Function to query Elasticsearch and get document count for a given time range\n",
        "def get_document_count(index_pattern, start_time, end_time):\n",
        "    range_query = {\n",
        "      \"range\": {\n",
        "        \"@timestamp\": {\n",
        "          \"gte\": start_time,\n",
        "          \"lt\": end_time\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    result = es.search(index=index_pattern, query=doubleQuoteDict(range_query), params={\"track_total_hits\":\"true\"} )\n",
        "    return result['hits']['total']['value']"
      ],
      "metadata": {
        "id": "HB-dXxVD5dv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now let's get the average doc size."
      ],
      "metadata": {
        "id": "wjx_C44_5k8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# before looking at the previous N days, let's inspect cat indices index_pattern for a doc count, and avg size\n",
        "#\n",
        "resp = es.cat.indices( index=index_pattern, format=\"json\",bytes=\"b\" )\n",
        "\n",
        "temp_total_docs = 0\n",
        "temp_total_pri = 0\n",
        "new_avg_doc = 0\n",
        "for each_index in resp:\n",
        "  if( int( each_index[\"pri.store.size\"] ) != 0 ):\n",
        "    temp_total_docs+= int( each_index[\"docs.count\"] )\n",
        "    temp_total_pri+= int( each_index[\"pri.store.size\"] )\n",
        "new_avg_doc = temp_total_pri / temp_total_docs\n",
        "print( \"total docs = \", temp_total_docs)\n",
        "print( \"total pri size = \", temp_total_pri)\n",
        "print ( \"avg doc size = \", new_avg_doc )"
      ],
      "metadata": {
        "id": "GCaRoWfL5nC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's go through and look at the number of docs per day"
      ],
      "metadata": {
        "id": "M4QgjAFi5tlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily=[]\n",
        "periods=[]\n",
        "while( last_n_days >= 1 ):\n",
        "  date_n1_days_ago = datetime.now() - timedelta( days=(last_n_days+1) )\n",
        "  date_n_days_ago = datetime.now() - timedelta( days=last_n_days )\n",
        "  print ( \"start = \" + str(date_n1_days_ago) )\n",
        "  print ( \"end = \" + str(date_n_days_ago) )\n",
        "  print ( \"index pattern - \" + index_pattern )\n",
        "  doc_count = get_document_count(index_pattern, date_n1_days_ago, date_n_days_ago)\n",
        "  print(\"%d docs \" % doc_count)\n",
        "  gigs = (doc_count * new_avg_doc) / 1024 / 1024 / 1024\n",
        "  daily.append( gigs )\n",
        "  periods.append( date_n_days_ago.strftime(\"%m-%d\") )\n",
        "  mb = (doc_count * new_avg_doc) / 1024 / 1024\n",
        "  print(\"in gigs = \" + str(gigs) + \", or in mb = \" + str(mb) + \", or in bytes = \"+ str(doc_count*new_avg_doc)  )\n",
        "  last_n_days = last_n_days - 1\n",
        "\n",
        "plt.bar( periods, daily, label=\"Daily Total\", color='b')\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Volume\")\n",
        "plt.title(\"Ingest Volume Per day in GB\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f78ivhxM5xjc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}